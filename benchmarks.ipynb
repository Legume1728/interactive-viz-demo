{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "from ipywidgets import interact, interactive_output\n",
    "from utils import project_root, run_benchmark\n",
    "import importlib\n",
    "\n",
    "\n",
    "def title_widget(title):\n",
    "    return widgets.HTML(value=f\"<div style='font-size: 24px; margin-left: 12px'>{title}</div>\")\n",
    "\n",
    "benchmarks = sorted([\n",
    "    os.path.splitext(filename)[0]\n",
    "    for filename in os.listdir(os.path.join(project_root, 'benchmarks_code'))\n",
    "    if filename not in ('__pycache__', '.ipynb_checkpoints')\n",
    "])\n",
    "\n",
    "def benchmark_widget(value, *args, **kwargs):\n",
    "    return widgets.Dropdown(\n",
    "        *args,\n",
    "        options=benchmarks,\n",
    "        value=value if value else benchmarks[0],\n",
    "        description='Benchmark:',\n",
    "        disabled=False,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "def read_benchmark_results(benchmark):\n",
    "    with open(f'benchmarks_results/{benchmark}.json') as f:\n",
    "        results = json.loads(f.read())\n",
    "    df = pl.DataFrame({'elapsed': results['elapsed']}).with_columns(\n",
    "        (pl.col('elapsed') * 1000).alias('elapsed_ms')\n",
    "    )\n",
    "    del results['elapsed']\n",
    "    return results, df\n",
    "\n",
    "def agg_benchmark_results(meta, df):\n",
    "    num_operations = meta['num_operations']\n",
    "    return df.select(\n",
    "        pl.col('elapsed_ms').median().alias('median (ms)'),\n",
    "        pl.col('elapsed_ms').quantile(0.95).alias('q95 (ms)'),\n",
    "    ).with_columns(\n",
    "        pl.lit(num_operations).alias('num_ops'),\n",
    "        (pl.col('median (ms)') / num_operations).alias('median_ms_per_op'),\n",
    "        (pl.col('q95 (ms)') / num_operations).alias('q95_ms_per_op'),\n",
    "    )\n",
    "\n",
    "# save last selection so if we refresh, we don't have to keep re-selecting it\n",
    "last_analyzed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2faf6274e7408f963ef87850b4e1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-size: 24px; margin-left: 12px'>Benchmark Output</div>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41136b1f94594c418974d14b0385b7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Benchmark:', index=2, options=('dictionary_reads', 'file_r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(title_widget('Benchmark Output'))\n",
    "b_widget = benchmark_widget(last_analyzed)\n",
    "\n",
    "def plot_benchmark(benchmark):\n",
    "    global last_analyzed\n",
    "    last_analyzed = benchmark\n",
    "\n",
    "    try:\n",
    "        meta, df = read_benchmark_results(benchmark)\n",
    "    except:\n",
    "        print('No data available')\n",
    "        plt.clf()\n",
    "        return\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # df = pl.read_csv('results/simple_ops.csv')\n",
    "    plot = sns.kdeplot(x='elapsed_ms', data=df, ax=axes[0])\n",
    "    plot.set_title(f'{benchmark} - Kernel Density Estimation')\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plot = sns.lineplot(x='index', y='elapsed_ms', data=df.with_row_index(), ax=axes[1])\n",
    "    plot.set_title(f'{benchmark} - Elapsed Time')\n",
    "\n",
    "    # plt.ylim(0)  # enable this to start y-axis at 0\n",
    "    plt.show()\n",
    "\n",
    "    print(agg_benchmark_results(meta, df))\n",
    "\n",
    "def run_benchmark_and_plot(benchmark, output):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print('running benchmark:', benchmark)\n",
    "        run_benchmark(benchmark)\n",
    "        plot_benchmark(benchmark)\n",
    "\n",
    "out = interactive_output(plot_benchmark, {'benchmark': b_widget})\n",
    "\n",
    "run_button = widgets.Button(description='Run Benchmark')\n",
    "run_button.on_click(lambda _: run_benchmark_and_plot(b_widget.value, out))\n",
    "top_bar = widgets.HBox([b_widget, run_button])\n",
    "\n",
    "display(widgets.VBox([top_bar, out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0f9160cba54839bd0358a3818c6ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-size: 24px; margin-left: 12px'>Benchmark Comparison</div>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfcb1dc2e28487b9614c287bd72ea70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(Dropdown(description='Benchmark:', options=('dictionary_reads', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(title_widget('Benchmark Comparison'))\n",
    "\n",
    "def plot_benchmark_kde_only(benchmark):\n",
    "    if not benchmark:\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        meta, df = read_benchmark_results(benchmark)\n",
    "    except:\n",
    "        print('no data available')\n",
    "        plt.clf()\n",
    "        return\n",
    "    \n",
    "    plt.figure()\n",
    "    plot = sns.kdeplot(x='elapsed_ms', data=df)\n",
    "    plot.set_title(f'{benchmark} - Kernel Density Estimation')\n",
    "    plt.show()\n",
    "    print(agg_benchmark_results(meta, df))\n",
    "\n",
    "def run_benchmark_and_compare(benchmark, output):\n",
    "    print('running benchmark:', benchmark)\n",
    "    run_benchmark(benchmark)\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        plot_benchmark(benchmark)\n",
    "\n",
    "def show_one():\n",
    "    b_widget = benchmark_widget(None)\n",
    "\n",
    "    out = interactive_output(plot_benchmark_kde_only, {'benchmark': b_widget})\n",
    "    run_button = widgets.Button(description='Run Benchmark')\n",
    "    run_button.on_click(lambda _: run_benchmark_and_compare(b_widget.value, out))\n",
    "\n",
    "    control_panel = widgets.HBox([b_widget, run_button])\n",
    "    return widgets.VBox([control_panel, out])\n",
    "\n",
    "display(widgets.HBox([show_one(), show_one()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
